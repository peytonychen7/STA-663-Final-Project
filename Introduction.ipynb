{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "The dimensionality of representation is a critical question to solve in unsupervised learning when we try to represent objects with multiple latent features. One method to solve this question is to apply a Bayesian latent feature model where the prior is used to represent the number of latent features. The Indian buffet process is an efficient stochastic process that can generate a prior for a model to represent objects with an infinite number of latent features. In this paper, we implement the basic algorithm of the Indian Buffet process and explore ways to optimize the algorithm. We then test the algorithm using simulated data sets and real data sets and compare the algorithm with two competing algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Unsupervised learning techniques have gained attention in academia and the industry due to their application in a variety of fields, such as image and pattern recognition, cancer research, consumer research, etc (Bouguila et al, 2005; ISLR). These techniques can help us identify the properties of objects even in the absence of response variables. The properties of these objects can be better captured if we use multiple latent features to represent the objects (Griffiths &  Ghahramani, 2005). As we work with latent features, one question we often need to consider is how many latent features do we need to use to represent the objects (Griffiths &  Ghahramani, 2005). The number of latent features can be finite or infinite. If we assume the dimension is infinite, one way to determine the latent structure is to use a Bayesian latent feature model, in which we use a prior distribution to represent the number of latent features needed, and use the likelihood function to analyze how these latent features are associated with the objects in the data set. The Indian buffet process provides an efficient way to generate a prior distribution for a latent feature model over equivalence classes of binary matrices with a finite number of rows but potentially an infinite number of columns. Such a model can be used to represent each object with a large number of latent features. \n",
    "\n",
    "One of the applications of the Indian buffet process is image processing. For example, Dang and Chainais applied the Indian buffet process as a prior and proposed a Bayesian nonparametric approach called Indian buffet process dictionary learning. The algorithm was applied to image inpainting and compressive sensing (Dang & Chainais, 2017). \n",
    "\n",
    "In this paper, we implement the algorithm of the Indian buffet process described in the paper titled \"Infinite Latent Feature Models and the Indian Buffet Process\" by Thomas L. Griffiths and Zoubin Ghahramani. We explore ways to make the algorithm more efficient using computational techniques in Python and test the algorithm using simulated data and real-world data. We also compare the efficiency of our algorithm with two competing algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Bouguila, Nizar, and Djemel Ziou. “Using Unsupervised Learning of a Finite Dirichlet Mixture Model to Improve Pattern Recognition Applications.” Pattern Recognition Letters, vol. 26, no. 12, 2005, pp. 1916–1925., doi:10.1016/j.patrec.2005.03.016. \n",
    "\n",
    "Dang, Hong-Phuong, and Pierre Chainais. “Indian Buffet Process Dictionary Learning: Algorithms and Applications to Image Processing.” International Journal of Approximate Reasoning, vol. 83, 2017, pp. 1–20., doi:10.1016/j.ijar.2016.12.010. \n",
    "\n",
    "Griffiths, Thomas L., and Zoubin Ghahramani. “Infinite Latent Feature Models and the Indian Buffet Process.” 2005. \n",
    "\n",
    "An Introduction to Statistical Learning: with Applications in R, by Gareth James et al., Springer, 2021, pp. 373–374. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
